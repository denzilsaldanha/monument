{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning - Mobile Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denzilsaldanha/monument/blob/master/Transfer_Learning_Mobile_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzxpi3esSMEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2I5X0dB3Xz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "count = 0\n",
        "for folder in os.listdir('drive/My Drive/train_sample_images/'):\n",
        "    for file in os.listdir('drive/My Drive/train_sample_images/'+str(folder)):\n",
        "        if file.endswith('.jpg') or file.endswith('.mpo'):\n",
        "            try:\n",
        "                img = Image.open('drive/My Drive/train_sample_images/'+str(folder)+'/'+str(file)) # open the image file\n",
        "                img.verify() # verify that it is, in fact an image\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                count +=1\n",
        "                os.remove('drive/My Drive/train_sample_images/'+str(folder)+'/'+str(file))\n",
        "                print('Bad file: ', str(file))\n",
        "                \n",
        "                \n",
        "print(\"CHECKED ALL FILES\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG9Enjyi9g2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.applications.mobilenetv2 import MobileNetV2, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "base_model=MobileNetV2(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(150,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "#specify the inputs\n",
        "#specify the outputs\n",
        "#now a model has been created based on our architecture\n",
        "layers = 0\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True\n",
        "    layers += 1\n",
        "print(layers)\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2) #included in our dependencies\n",
        "\n",
        "# train_generator=train_datagen.flow_from_directory('./train/', # this is where you specify the path to the main data folder\n",
        "#                                                  target_size=(224,224),\n",
        "#                                                  color_mode='rgb',\n",
        "#                                                  batch_size=32,\n",
        "#                                                  class_mode='categorical',\n",
        "#                                                  shuffle=True)\n",
        "\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('drive/My Drive/train_sample_images',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 128,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                subset ='training')\n",
        "validation_set = train_datagen.flow_from_directory(\n",
        "    'drive/My Drive/train_sample_images', # same directory as training data\n",
        "    target_size=(224,224),\n",
        "    batch_size=128,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# In[33]:\n",
        "epochs_run = 0\n",
        "\n",
        "# if glob.glob('drive/My Drive/GOOGLE_MONUMENT/weights-improvement-mobile_net-[0-9]{1,2}[.-].*'):\n",
        "#   #max(glob.glob('drive/My Drive/GOOGLE_MONUMENT/weights-improvement-mobile-net-[0-9][0-9]*'))\n",
        "#   weight_to_be_loaded = max(glob.glob('drive/My Drive/GOOGLE_MONUMENT/weights-improvement-mobile-net-[0-9]{1,2}[.-].*'))\n",
        "#   weight_to_be_loaded = model.load_weights('/drive/My Drive/GOOGLE_MONUMENT/weights-improvement-mobile_net-01-0.36.hdf5')\n",
        "#   model.load_weights(weight_to_be_loaded)\n",
        "# #   epochs_run = int(weight_to_be_loaded[62:64])\n",
        "# if os.path.isfile('/drive/My Drive/GOOGLE_MONUMENT/model_h5_mobile_net.h5'): # if thats the case then there must be a read error somewhere.\n",
        "#   model.load_weights('/drive/My Drive/GOOGLE_MONUMENT/model_h5_mobile_net.h5')\n",
        "#   epochs_run = 5\n",
        "#   # Change this to the file saved by the second epoch and initiallize epochs run to 1+ the number of epochs run. \n",
        "#   #Basically it should start from the 3rd epoch if youre loading the 2 epoch weights\n",
        "# else:\n",
        "#   print('MODEL NOT FOUND')\n",
        "  \n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "\n",
        "csv_file = 'drive/My Drive/GOOGLE_MONUMENT/log_for_mobile_net_starting_from_epoch_'+str(epochs_run)+'.csv'\n",
        "checkpoint=\"drive/My Drive/GOOGLE_MONUMENT/weights-improvement-mobile_net-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint, monitor='val_acc', verbose=1, mode='max')\n",
        "csv_logger = CSVLogger(csv_file, append=True, separator=';')\n",
        "callbacks_list = [csv_logger,checkpoint]\n",
        "\n",
        "#model.summary()\n",
        "step_size_train=training_set.n//training_set.batch_size\n",
        "val_steps = validation_set.n//validation_set.batch_size\n",
        "model.fit_generator(generator=training_set,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=5, validation_data = validation_set,validation_steps=val_steps,\n",
        "                   callbacks =callbacks_list,initial_epoch = epochs_run)\n",
        "\n",
        "\n",
        "#print(\"%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
        "model.save('drive/My Drive/GOOGLE_MONUMENT/model_mobilenet.hdf5')\n",
        "model.save_weights(\"drive/My Drive/GOOGLE_MONUMENT/model_h5_mobile_net.h5\")\n",
        "print(\"Saved model to disk\") \n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"drive/My Drive/GOOGLE_MONUMENT/model_mobilenet.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EbaDvzLNGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}